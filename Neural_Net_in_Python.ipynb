{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks in 100 lines of pure Python\n",
    "- [blog_link](https://eisenjulian.github.io/deep-learning-in-100-lines/)\n",
    "- [Pytorch nn module tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Solarize_Light2',\n",
       " '_classic_test',\n",
       " 'bmh',\n",
       " 'classic',\n",
       " 'dark_background',\n",
       " 'fast',\n",
       " 'fivethirtyeight',\n",
       " 'ggplot',\n",
       " 'grayscale',\n",
       " 'seaborn',\n",
       " 'seaborn-bright',\n",
       " 'seaborn-colorblind',\n",
       " 'seaborn-dark',\n",
       " 'seaborn-dark-palette',\n",
       " 'seaborn-darkgrid',\n",
       " 'seaborn-deep',\n",
       " 'seaborn-muted',\n",
       " 'seaborn-notebook',\n",
       " 'seaborn-paper',\n",
       " 'seaborn-pastel',\n",
       " 'seaborn-poster',\n",
       " 'seaborn-talk',\n",
       " 'seaborn-ticks',\n",
       " 'seaborn-white',\n",
       " 'seaborn-whitegrid',\n",
       " 'tableau-colorblind10']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(mpl.style.available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param Class\n",
    "\n",
    "We can start with a class that encapsulates \n",
    "- tensor\n",
    "- its gradients. \n",
    "\n",
    "The tensor can be anything like numpy array or torch array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter():\n",
    "    def __init__(self, tensor):\n",
    "        self.tensor = tensor\n",
    "        self.gradient = np.zeros_like(self.tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Class\n",
    "\n",
    "Now we can create the layer class, the key idea is that during a forward pass (`Forward()`) we return both \n",
    "\n",
    "- layer output \n",
    "- `function`\n",
    "\n",
    "The `function` will have the following signature:\n",
    "\n",
    "```py\n",
    "def function(input):\n",
    "    \"\"\"\n",
    "    input (tensor): gradient of the loss with respect to the outputs\n",
    "    return (tensor): the gradient with respect to the inputs, \n",
    "                    updating the weight gradients in the process\n",
    "    \"\"\"\n",
    "    output = do_operation(input)\n",
    "    return output\n",
    "\n",
    "```\n",
    "\n",
    "This is because while evaluating the model layer by layer there's no way to calculate the gradients if we don't know the final loss yet, instead the best thing you can do is return a function that CAN calculate the gradient later. And that function will only be called after we completed the forward evaluation, when you know the loss and you have all the necessary info to compute the gradients in that layer.\n",
    "\n",
    "\n",
    "The training process will then have three steps, calculate the forward step, then the backward steps accumulate the gradients, and finally updating the weights. It’s important to do this at the end\tsince weights can be reused in multiple layers and we don’t want to mutate the weights before time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.parameters = []\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X, lambda D: D\n",
    "\n",
    "    def build_param(self, tensor):\n",
    "        \"\"\"\n",
    "        tensor (numpy matrix)\n",
    "        return:\n",
    "            param (Parameter)\n",
    "        \"\"\"\n",
    "        param = Parameter(tensor)\n",
    "        self.parameters.append(param)\n",
    "        return param\n",
    "    \n",
    "    def update(self, optimizer):\n",
    "        for param in self.parameters: optimizer.update(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's standard to delegate the job of updating the parameters to an optimizer, which receives an instance of a parameter after every batch. The simplest and most known optimization method out there is the mini-batch stochastic gradient descent\n",
    "\n",
    "### Code Analysis\n",
    "Also look at line 6, where it's returning a lambda. Here it's returning a lambda function that can be applied later with the appropriate argument. \n",
    "\n",
    "How a returned lambda function can work? \n",
    "\n",
    "Lets see an example\n",
    "\n",
    "```py\n",
    "def fun(n):\n",
    "    \"\"\"\n",
    "    return a lambda function with the increment size\n",
    "    \"\"\"\n",
    "    return lambda x: x+n\n",
    "\n",
    "x = 3\n",
    "inc3 = fun(3)\n",
    "inc3(x) ## this will increase the x's value by 3\n",
    "ans: 6\n",
    "\n",
    "inc5 = fun(5)\n",
    "inc5(x) ## this will increase the x's value by 3\n",
    "ans: 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDOptimizer():\n",
    "    def __init__(self, lr=0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, param):\n",
    "        \"\"\"\n",
    "        the tensors are updated, but not the gradients. they are filled with 0. Why ????\n",
    "        look at the backward() definition in Class Linear. In the backward(), the gradients are updated.\n",
    "        \"\"\"\n",
    "        param.tensor -= self.lr * param.gradient\n",
    "        param.gradient.fill(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next build our `Linear Layer` extending the `Class Layer`\n",
    "\n",
    "## Linear Class\n",
    "\n",
    "For reference let's look at the `Layer class`, which the `Linear class` is extending\n",
    "```py\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.parameters = []\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X, lambda D: D\n",
    "\n",
    "    def build_param(self, tensor):\n",
    "        \"\"\"\n",
    "        tensor (numpy matrix)\n",
    "        return:\n",
    "            param (Parameter)\n",
    "        \"\"\"\n",
    "        param = Parameter(tensor)\n",
    "        self.parameters.append(param)\n",
    "        return param\n",
    "    \n",
    "    def update(self, optimizer):\n",
    "        for param in self.parameters: optimizer.update(param)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        \"\"\"\n",
    "        inputs (int): input dimension\n",
    "        outputs (int): output dimension\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        tensor = np.random.randn(inputs, outputs) * np.sqrt(1 / inputs)\n",
    "        self.weights = self.build_param(tensor)\n",
    "        self.bias = self.build_param(np.zeros(outputs))\n",
    "\n",
    "    def forward(self, X):\n",
    "        def backward(D):\n",
    "            self.weights.gradient += X.T @ D\n",
    "            self.bias.gradient += D.sum(axis=0)\n",
    "            return D @ self.weights.tensor.T\n",
    "        \n",
    "        return X @ self.weights.tensor +  self.bias.tensor, backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Analysis\n",
    "\n",
    "**line 8**\n",
    "\n",
    "We are initializing the weights here with `Xavier initialisation` (by multiplying with `1/sqrt(n)`), where n is the input dimension\n",
    "\n",
    "**Line 9, 10**\n",
    "\n",
    "the build param is returning a Parameter object which has a tensor and the gradient. The tensor is filled with the input tensor. But the gradient is filled with `0` intially.\n",
    "\n",
    "**Line 14-16**\n",
    "\n",
    "the `backward()` definition is something similar to \n",
    "\n",
    "```py\n",
    "def outfun(x):\n",
    "    def infun(n):\n",
    "        print('process infun() running ...')\n",
    "        return x*n\n",
    "    return 5*x, infun\n",
    "\n",
    "x1 = 10\n",
    "x2 = 11\n",
    "z, y = outfun(x1)\n",
    "print(y(z))\n",
    "\n",
    "z, y = outfun(x2)\n",
    "print(y(z))\n",
    "Ans:\n",
    "process infun() running ...\n",
    "500\n",
    "process infun() running ...\n",
    "605\n",
    "```\n",
    "\n",
    "Here the logic is outfun will return the `5*x` and also the **partial funciton defition** for `infun()`. \n",
    "\n",
    "Why **partial function definition**?: \n",
    "\n",
    "- Because when the definition of `infun(n)` is generated, it doesn't know the `n`. But it receives the `x` from `outfun(x)`. So `infun()` definition is partially generated when `outfun()` returns `infun`. Later, when we call `y(z)` then `y == infun` and `n == z` and then `infun(z)` is executed and it gives `500`. It means that the `infun()` definition is not static. Rather it's dynamic. Because it's one part is bound to the input of the `outfun()`. Thus for different `outfun(10)`, `outfun(11)` call, output of `infun(z)` will be different. \n",
    "\n",
    "Now this same logic is running behind the `Forward()` and `backward()` definition. For each layer there should be a `Forward()` and `backward()` function. However only catch is the `backward()` can only be called after `Forward()` is finished - giving us the final loss. \n",
    "\n",
    "> \"..This is because while evaluating the model layer by layer there's no way to calculate the gradients if we don't know the final loss yet, instead the best thing you can do is return a function that CAN calculate the gradient later. And that function will only be called after we completed the forward evaluation, when you know the loss and you have all the necessary info to compute the gradients in that layer...\"\n",
    "\n",
    "\n",
    "\n",
    "Now, the next most used types of layers are activations, which are non-linear point-wise functions. The Jacobian of a point-wise function is diagonal, which means that when multiplied by the gradient it also acts a `point-wise multiplication`.\n",
    "\n",
    "The **@** operator:\n",
    "\n",
    "> numpy overloaded @ operator for matrix multiplication\n",
    "\n",
    "It basically does the matrix multiplication\n",
    "\n",
    "```py\n",
    "a = np.random.randint(low=0, high=10,size=(4,3))\n",
    "c = np.random.randint(low=0, high=10,size=(3,4))\n",
    "\n",
    "np.dot(a, c)\n",
    "\n",
    "np.matmul(a, c) # n is 4, k is 3, m is 4\n",
    "\n",
    "a @ c\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu(Layer):\n",
    "    def forward(self, X):\n",
    "        mask = X > 0\n",
    "        return X * mask, lambda D: D * mask\n",
    "    \n",
    "class ReLu2(Layer):\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        mask (bool:ndarray): True if X > 0 else False\n",
    "        \n",
    "        X*mask (int/float ndarray): x_ij if mask_ij == True else 0 \n",
    "        \"\"\"\n",
    "        mask = X > 0\n",
    "        \n",
    "        def backward(D):\n",
    "            return D * mask\n",
    "        \n",
    "        return X * mask, backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Analysis\n",
    "\n",
    "Both the definition are same. Look closely and see `ReLu2::Forward()` is returning a **named function** `backward()`, whereas `ReLy::Forward()` is returning an **unnamed function** lambda\n",
    "\n",
    "\n",
    "```py\n",
    "a = np.random.randint(low=-10, high=10,size=(4,3))\n",
    "c = np.random.randint(low=-10, high=10,size=(4,3))\n",
    "print(a)\n",
    "mask = a > 0\n",
    "print(mask)\n",
    "print(c * mask) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def forward(self, X):\n",
    "        S = 1 / (1 + np.exp(-X))\n",
    "        def backward(D):\n",
    "            return D * S * (1 - S)\n",
    "        \n",
    "        return S, backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Magic: Sequential Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- many layers in sequence\n",
    "- traverse those layers in sequence execute Forward() for each layer\n",
    "  - save the returned `backward()` of Forward() for each layer in list: list_backward \n",
    "  - iterate list_backward in reverse order\n",
    "    - get all the way to gradient w.r.t the first layer input and return it.\n",
    "    \n",
    "This is where the **magic** happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(Layer):\n",
    "    def __init__(self, *layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for layer in layers:\n",
    "            self.parameters.extend(layer.parameters)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        backpropos (list): contains all the backward() of all the layers\n",
    "        \n",
    "        So the backward() of Sequential Class is actually running all the backward() \n",
    "            of all the layer class in reverse order \n",
    "        \"\"\"\n",
    "        backprops = []\n",
    "        Y = X\n",
    "        for layer in self.layers:\n",
    "            Y, backprop = layer.forward(Y)\n",
    "            backprops.append(backprop) ## Y is not appended, the final Y is returned\n",
    "        \n",
    "        def backward(D):\n",
    "            for backprop in reversed(backprops): \n",
    "                D = backprop(D)\n",
    "            return D\n",
    "        return Y, backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE Loss\n",
    "As we mentioned earlier, we will need a way to calculate the loss function associated with a batch of samples, and its gradient. One example would be MSE loss, typically used in regression problems, and it can be implemented in this manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(Yp, Yt):\n",
    "    \"\"\"\n",
    "    returns the loss and the derivative of loss\n",
    "    \"\"\"\n",
    "    diff = Yp - Yt\n",
    "    return np.square(diff).mean(), 2 * diff / len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Class\n",
    "\n",
    "Almost there now, we have two types of layers and a way to combine them, so how does the training loop look like. We can use an API similar to scikit-learn or keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, loss, optimizer):\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def fit_batch(self, X, Y):\n",
    "        Y_, backward = self.model.forward(X)\n",
    "        L, D = self.loss(Y_, Y)\n",
    "        backward(D)\n",
    "        self.model.update(self.optimizer)\n",
    "        return L\n",
    "\n",
    "    def fit(self, X, Y, epochs, bs):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            p = np.random.permutation(len(X))\n",
    "            X, Y = X[p], Y[p]\n",
    "            loss = 0.0\n",
    "            for i in range(0, len(X), bs):\n",
    "                loss += self.fit_batch(X[i:i + bs], Y[i:i + bs])\n",
    "            losses.append(loss)\n",
    "    \n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80.08798996425271,\n",
       " 10.679548725998474,\n",
       " 1.9042406281155577,\n",
       " 0.3864093357335405,\n",
       " 0.08534169977526683,\n",
       " 0.019765956435212517,\n",
       " 0.0047690554650691415,\n",
       " 0.00118407972710938,\n",
       " 0.00029472626669883455,\n",
       " 8.052980923992693e-05]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randn(100, 10)\n",
    "W = np.random.randn(10, 1)\n",
    "B = np.random.randn(1)\n",
    "Y = X @ W + B\n",
    "\n",
    "N_EPOCHS = 10\n",
    "model = Linear(10, 1)\n",
    "learner = Learner(model, mse_loss, SGDOptimizer(lr=0.05))\n",
    "loss = learner.fit(X, Y, epochs=N_EPOCHS, bs=10)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mpl.style.context('seaborn-talk'):\n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    plt.plot(list(range(N_EPOCHS)), loss, color='b', alpha=0.5, label='train_loss')\n",
    "    # plt.plot(list(range(N_EPOCHS)), valid_ppl, color='r', alpha=0.5, label='valid_ppl')\n",
    "    plt.title(\"LOSS vs Epoch\",fontweight=\"bold\")\n",
    "    plt.xlabel(\"Epoch\",fontweight=\"bold\")\n",
    "    plt.ylabel(\"Loss\",fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Matrix Error 0.0034037229602633585\n",
      "Bias error 0.00029977678907489036\n"
     ]
    }
   ],
   "source": [
    "#@title A simple linear dataset\n",
    "num_features = 10 #@param {type:\"slider\", min:5, max:100, step:1}\n",
    "num_samples = 100 #@param {type:\"slider\", min:10, max:1000, step:1}\n",
    "epochs = 10 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "batch_size = 10 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "learning_rate = 0.05 #@param {type:\"slider\", min:0.001, max:1.0, step:0.001}\n",
    "\n",
    "m = Linear(num_features, 1)\n",
    "model = Sequential(m)\n",
    "l = Learner(model, mse_loss, SGDOptimizer(lr=learning_rate))\n",
    "X = np.random.randn(num_samples, num_features)\n",
    "W = np.random.randn(num_features, 1)\n",
    "B = np.random.randn(1)\n",
    "Y = X @ W + B + 0.01 * np.random.randn(num_samples, 1)\n",
    "#plt.plot(l.fit(X, Y, epochs=epochs, bs=batch_size))\n",
    "with mpl.style.context('seaborn-talk'):\n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    plt.plot(list(range(N_EPOCHS)), l.fit(X, Y, epochs=epochs, bs=batch_size), color='b', alpha=0.5, label='train_loss')\n",
    "    # plt.plot(list(range(N_EPOCHS)), valid_ppl, color='r', alpha=0.5, label='valid_ppl')\n",
    "    plt.title(\"LOSS vs Epoch\",fontweight=\"bold\")\n",
    "    plt.xlabel(\"Epoch\",fontweight=\"bold\")\n",
    "    plt.ylabel(\"Loss\",fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "print('Weight Matrix Error', np.linalg.norm(m.weights.tensor - W))\n",
    "print('Bias error', np.abs(m.bias.tensor - B)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check that the learned weights coincide with the true ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002465486371045121 0.000264120596444567\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(model.weights.tensor - W), (model.bias.tensor - B)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (2,1) doesn't match the broadcast shape (2,50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-fa5d93fdc7ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     SGDOptimizer(lr=one_layer_learning_rate)).fit(X, Y, epochs=epochs, bs=one_layer_batch_size)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m losses2 = Learner(\n",
      "\u001b[0;32m<ipython-input-67-c472e565b3a7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, epochs, bs)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-c472e565b3a7>\u001b[0m in \u001b[0;36mfit_batch\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mY_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-36ee4d688491>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(D)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbackprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackprops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-10cae2a014d2>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(D)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (2,1) doesn't match the broadcast shape (2,50)"
     ]
    }
   ],
   "source": [
    "#@title A non-linear dataset\n",
    "num_samples = 1000 #@param {type:\"slider\", min:100, max:10000, step:1}\n",
    "epochs = 50 #@param {type:\"slider\", min:1, max:200, step:1}\n",
    "\n",
    "one_layer_batch_size = 50 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "one_layer_learning_rate = 0.01 #@param {type:\"slider\", min:0.001, max:1.0, step:0.001}\n",
    "\n",
    "two_layer_batch_size = 50 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "two_layer_learning_rate = 0.3 #@param {type:\"slider\", min:0.001, max:1.0, step:0.001}\n",
    "hidden_neurons = 10 #@param {type:\"slider\", min:1, max:200, step:1}\n",
    "\n",
    "X = np.random.randn(num_samples, 2)\n",
    "Y = X[:, 0] * X[:, 1]\n",
    "\n",
    "losses1 = Learner(\n",
    "    Sequential(Linear(2, 1)), \n",
    "    mse_loss, \n",
    "    SGDOptimizer(lr=one_layer_learning_rate)).fit(X, Y, epochs=epochs, bs=one_layer_batch_size)\n",
    "\n",
    "losses2 = Learner(\n",
    "    Sequential(\n",
    "        Linear(2, hidden_neurons), \n",
    "        Sigmoid(), \n",
    "        Linear(hidden_neurons, 1)\n",
    "    ), mse_loss, SGDOptimizer(lr=two_layer_learning_rate)).fit(X, Y, epochs=epochs, bs=two_layer_batch_size)\n",
    "\n",
    "plt.plot(losses1)\n",
    "plt.plot(losses2)\n",
    "plt.legend(['1 Layer', '2 Layers'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
